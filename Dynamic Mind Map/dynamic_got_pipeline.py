# dynamic_got_pipeline.py
import os
import json
import requests
from typing import Dict, Any, List

from thought_graph import ThoughtGraph, extract_first_json
import prompts as P

API_URL = "https://api.siliconflow.cn/v1/chat/completions"
DEFAULT_MODEL = "Qwen/QwQ-32B"  # ä½ ä¹Ÿå¯ä»¥æ¢æˆåˆ«çš„å…¼å®¹æ¨¡å‹

class LLM:
    def __init__(self, api_key: str, model: str = DEFAULT_MODEL, url: str = API_URL, timeout: int = 60):
        self.api_key = api_key
        self.model = model
        self.url = url
        self.timeout = timeout

    def chat(self, system_prompt: str, user_prompt: str) -> str:
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]
        }
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        resp = requests.post(self.url, json=payload, headers=headers, timeout=self.timeout)
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"]

# ---------------- æ ¸å¿ƒæµç¨‹ ----------------

def generate_graph(llm: LLM, question: str) -> ThoughtGraph:
    """
    ç¬¬ä¸€æ¬¡ APIï¼šè¯·æ¨¡å‹ç”Ÿæˆâ€œæ€ç»´å›¾ JSONâ€ï¼Œå¹¶è§£æ+æ ¡éªŒã€‚
    """
    user_prompt = P.GRAPH_GEN_USER_TEMPLATE.format(question=question)
    raw = llm.chat(P.GRAPH_GEN_SYSTEM, user_prompt)

    json_str = extract_first_json(raw)
    if not json_str:
        raise ValueError("æœªèƒ½ä»å¤§æ¨¡å‹è¾“å‡ºä¸­æå–JSONï¼Œè¯·æ£€æŸ¥æç¤ºè¯æˆ–æ¨¡å‹è¾“å‡ºã€‚")

    tg = ThoughtGraph.from_json_str(json_str)
    report = tg.validate()
    if not report["valid"]:
        print("âš ï¸ å›¾è°±æ ¡éªŒé—®é¢˜ï¼š")
        for p in report["problems"]:
            print(" -", p)
    print("ğŸ“ˆ å›¾è°±æ‘˜è¦ï¼š", report["summary"])
    return tg

def answer_with_graph(llm: LLM, question: str, tg: ThoughtGraph) -> Dict[str, Any]:
    """
    ç¬¬äºŒæ¬¡ APIï¼šæŠŠâ€œç´§å‡‘ä¸‰å…ƒç»„â€å–‚ç»™æ¨¡å‹ï¼Œè¦æ±‚ä¸¥æ ¼åŸºäºå›¾è¿›è¡Œå›ç­”ã€‚
    """
    triples = tg.to_min_triples()
    triples_text = "\n".join(f"- {t}" for t in triples)

    user_prompt = P.ANSWER_USER_TEMPLATE.format(
        question=question,
        triples_text=triples_text
    )
    raw = llm.chat(P.ANSWER_SYSTEM, user_prompt)

    json_str = extract_first_json(raw)
    if not json_str:
        raise ValueError("æœªèƒ½ä»å›ç­”ä¸­æå–JSONã€‚")

    result = json.loads(json_str)
    return result

# ---------------- ä¸€è‡´æ€§æ ¡éªŒ ----------------

def coverage_check(tg: ThoughtGraph, result: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ ¡éªŒç‚¹ï¼š
    1) used_nodes/used_edges æ˜¯å¦å­˜åœ¨äºå›¾ä¸­
    2) è¦†ç›–åº¦ï¼šå›ç­”æ˜¯å¦è¦†ç›–æƒé‡Top-Kçš„è¾¹ï¼ˆé€šè¿‡åå­—åŒ…å«æ¥ç²—æ£€ï¼‰
    """
    problems: List[str] = []
    used_nodes = set(result.get("used_nodes", []))
    used_edges = set(result.get("used_edges", []))

    # 1) å¼•ç”¨å­˜åœ¨æ€§
    for nid in used_nodes:
        if nid not in tg.nodes:
            problems.append(f"å¼•ç”¨äº†ä¸å­˜åœ¨çš„èŠ‚ç‚¹ID: {nid}")
    for eid in used_edges:
        if eid not in tg.edges:
            problems.append(f"å¼•ç”¨äº†ä¸å­˜åœ¨çš„å…³ç³»ID: {eid}")

    # 2) è¦†ç›–Top-K è¾¹ï¼ˆK=3ï¼‰
    top_edges = sorted(tg.edges.values(), key=lambda e: e.weight, reverse=True)[:3]
    final_answer: str = result.get("final_answer", "")
    missed_important = []
    for e in top_edges:
        s = tg.nodes[e.source].name
        t = tg.nodes[e.target].name
        # ç²—ç•¥ï¼šç­”æ¡ˆé‡Œè‡³å°‘å‡ºç°ä»»ä¸€ç«¯ç‚¹åç§°
        if (s not in final_answer) and (t not in final_answer):
            missed_important.append(f"{e.id}:{s}-[{e.relation}]->{t}")

    return {
        "æ˜¯å¦é€šè¿‡": "æ˜¯" if not problems and not missed_important else "å¦",
        "ç»“æ„é—®é¢˜": problems or "æ— ",
        "é«˜æƒé‡å…³ç³»æœªè¦†ç›–": missed_important or "æ— ",
        "å»ºè®®": "è‹¥å­˜åœ¨æœªè¦†ç›–é«˜æƒé‡å…³ç³»ï¼Œè€ƒè™‘åœ¨ç­”æ¡ˆä¸­è¡¥å……ä¸å…¶ç›¸å…³çš„å»ºè®®æˆ–è¡ŒåŠ¨é¡¹ã€‚"
    }

# ---------------- è¿è¡Œå…¥å£ ----------------

def main():
    api_key = os.getenv("SILICONFLOW_API_KEY")
    if not api_key:
        raise RuntimeError("è¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ SILICONFLOW_API_KEY")

    llm = LLM(api_key=api_key)

    # ä½ å¯ä»¥æ¢æˆè‡ªå·±çš„çœŸå®ç”»åƒ/çº¦æŸ/ç›®æ ‡
    question = (
        "æˆ‘æœ‰3å¹´Pythonæ•°æ®åˆ†æç»éªŒï¼Œæœ¬ç§‘éCSã€‚æƒ³åœ¨æ–°èƒ½æºè¡Œä¸šï¼ˆä¼˜å…ˆå…‰ä¼/é£ç”µï¼‰æ‰¾æ•°æ®åˆ†æ/æ•°æ®å·¥ç¨‹å²—ä½ï¼Œ"
        "æœŸæœ›åœ¨ä¸Šæµ·æˆ–æ­å·ï¼Œæ„¿æ„æ¯å‘¨æŠ•å…¥10å°æ—¶å­¦ä¹ ã€‚è¯·ç»™å‡ºæŠ€èƒ½è¡¥é½ã€è¯ä¹¦å»ºè®®ã€é¡¹ç›®ç»„åˆå’Œ3ä¸ªæœˆè¡ŒåŠ¨è®¡åˆ’ã€‚"
    )

    print("== ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæ€ç»´å›¾ ==")
    tg = generate_graph(llm, question)
    print(tg.to_json())

    print("\n== ç¬¬äºŒæ­¥ï¼šåŸºäºå›¾å›ç­” ==")
    result = answer_with_graph(llm, question, tg)
    print(json.dumps(result, ensure_ascii=False, indent=2))

    print("\n== ç¬¬ä¸‰æ­¥ï¼šä¸€è‡´æ€§æ ¡éªŒ ==")
    report = coverage_check(tg, result)
    print(json.dumps(report, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()
